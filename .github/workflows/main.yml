name: Crawler

on:
  push:
    branches: master
  schedule:
    - cron: "*/30 * * * *" # every 30 minutes
jobs:
  crawl-channels:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - run: npm install
      - run: node crawl_channels.js
      - uses: actions/upload-artifact@v3
        with:
          name: artifacts
          path: ./artifacts
          retention-days: 1

  scrape-email:
    runs-on: ubuntu-latest
    needs: crawl-channels
    strategy:
      matrix:
        worker_id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # no of workers from config
    steps:
      - uses: actions/checkout@v2
      - uses: actions/download-artifact@v3
      - run: npm install
      - run: node scrape_email.js ${{ matrix.worker_id }}
      - uses: actions/upload-artifact@v3
        with:
          name: artifacts
          path: ./artifacts
          retention-days: 1

  update-data:
    runs-on: ubuntu-latest
    needs: scrape-email
    steps:
      - uses: actions/checkout@v2
      - uses: actions/download-artifact@v3
      - run: npm install
      - run: node merge_data.js

      - run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push

  generate-stats:
    runs-on: ubuntu-latest
    needs: update-data
    steps:
      - uses: actions/checkout@v2
      - run: npm install
      - run: node stats.js

      - run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push
